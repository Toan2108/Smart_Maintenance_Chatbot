import streamlit as st
import openai
import os
os.environ["TORCH_DISABLE_WATCHDOG"] = "1"
os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["HF_HOME"] = "/tmp"  # n∆°i l∆∞u cache model
os.environ["HF_DATASETS_CACHE"] = "/tmp"
os.environ["HF_METRICS_CACHE"] = "/tmp"

import numpy as np
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer

@st.cache_resource
def load_model():
    model = SentenceTransformer("all-MiniLM-L6-v2")
    return model

from sklearn.preprocessing import normalize
from utils import load_faiss_and_docs

# ‚úÖ Load API Key
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ‚úÖ C·∫•u h√¨nh giao di·ªán
st.set_page_config(page_title="Smart Maintenance Chatbot", layout="wide")
st.title("ü§ñ Smart Maintenance Chatbot")
st.markdown("Nh·∫≠p c√¢u h·ªèi k·ªπ thu·∫≠t ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ t·ª´ K·ªπ s∆∞ chuy√™n m√¥n.")

# ‚úÖ Load d·ªØ li·ªáu FAISS v√† vƒÉn b·∫£n
index, docs = load_faiss_and_docs()

# ‚úÖ Load m√¥ h√¨nh embedding
from utils import download_and_extract_model

# Load m√¥ h√¨nh t·ª´ local (ƒë√£ ƒë∆∞·ª£c gi·∫£i n√©n)
model_path = download_and_extract_model()
model = SentenceTransformer(model_path)

# ‚úÖ Nh·∫≠p c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
query = st.text_input("üõ†Ô∏è Nh·∫≠p c√¢u h·ªèi k·ªπ thu·∫≠t:")

if query:
    query_embedding = model.encode([query])
    query_embedding = normalize(query_embedding, axis=1)

    D, I = index.search(query_embedding, k=3)

    contexts = []
    for idx in I[0]:
        if 0 <= idx < len(docs):
            contexts.append(docs[idx])

    if not contexts:
        st.error("Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p.")
    else:
        st.subheader("üìé T√†i li·ªáu tham chi·∫øu:")
        for i, ctx in enumerate(contexts):
            st.markdown(f"**{i+1}.** {ctx}")
        context_text = "\n\n".join(contexts)
        prompt = f"""
B·∫°n l√† chuy√™n gia k·ªπ thu·∫≠t, k·ªπ s∆∞ B·∫£o tr√¨. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë th√¥ng tin k·ªπ thu·∫≠t li√™n quan:

{context_text}

C√¢u h·ªèi: {query}
Vui l√≤ng tr·∫£ l·ªùi ch√≠nh x√°c, r√µ r√†ng, ng·∫Øn g·ªçn. D·ª±a v√†o d·ªØ li·ªáu k·ªπ thu·∫≠t ·ªü tr√™n, ƒë·ªÅ xu·∫•t √≠t nh·∫•t 3 gi·∫£i ph√°p v√† c√≥ 1 gi·∫£i ph√°p ph√≤ng ng·ª´a, c√°c ƒë·ªÅ xu·∫•t ph·∫£i li√™n quan ƒë·∫øn n·ªôi dung c·ªßa c√¢u h·ªèi.
"""

        try:
            from openai import OpenAI
            client = OpenAI()

            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}]
            )
            answer = response.choices[0].message.content.strip()
            st.markdown("### ü§ñ K·∫øt qu·∫£ t·ª´ AI:")
            st.success(answer)
        except Exception as e:
            st.error(f"L·ªói khi g·ªçi OpenAI API: {e}")
