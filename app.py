import streamlit as st
import openai
import os
import pickle
import faiss
import numpy as np
import requests
import zipfile
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from utils import load_faiss_and_docs
import gdown  # th√™m th∆∞ vi·ªán n√†y ·ªü ƒë·∫ßu

# H√†m t·∫£i file zip t·ª´ Google Drive
def download_and_extract_model():
    model_url = "https://drive.google.com/uc?id=1GwQQmdZ2O2wGixLKiRk9MiMtBfToozll"  # ƒë√∫ng ƒë·ªãnh d·∫°ng gdown
    zip_path = "local_model.zip"
    extract_folder = "local_model"

    if not os.path.exists(extract_folder):
        # T·∫£i file zip b·∫±ng gdown
        gdown.download(model_url, zip_path, quiet=False)

        # Gi·∫£i n√©n file zip
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_folder)

        os.remove(zip_path)  # X√≥a file zip sau khi gi·∫£i n√©n

    return extract_folder

# Load API Key t·ª´ .env ho·∫∑c secrets
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# C·∫•u h√¨nh Streamlit
st.set_page_config(page_title="AI Chatbot B·∫£o Tr√¨", layout="wide")
st.title("ü§ñ Smart Maintenance Chatbot")
st.markdown("Chatbot h·ªó tr·ª£ k·ªπ thu·∫≠t vi√™n tra c·ª©u l·ªói & h∆∞·ªõng x·ª≠ l√Ω t·ª´ d·ªØ li·ªáu hu·∫•n luy·ªán n·ªôi b·ªô.")

# B∆∞·ªõc 1: T·∫£i d·ªØ li·ªáu t·ª´ Google Drive n·∫øu ch∆∞a c√≥
faiss_path, docs_path = load_faiss_and_docs()

# B∆∞·ªõc 2: Load FAISS index v√† d·ªØ li·ªáu g·ªëc
with open(docs_path, "rb") as f:
    docs = pickle.load(f)
index = faiss.read_index(faiss_path)

# B∆∞·ªõc 3: Nh·∫≠n c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
query = st.text_input("üí¨ Nh·∫≠p c√¢u h·ªèi k·ªπ thu·∫≠t ho·∫∑c l·ªói m√°y m√≥c:")

if query:
    # T·∫£i model local n·∫øu ch∆∞a c√≥
    model_path = download_and_extract_model()
    model = SentenceTransformer(model_path)
    query_embedding = model.encode([query])

    # FAISS t√¨m top 3 ƒëo·∫°n g·∫ßn nh·∫•t
    D, I = index.search(np.array(query_embedding), k=3)

    # X·ª≠ l√Ω d·ªØ li·ªáu n·∫øu l√† dict
    if isinstance(docs, dict):
        docs = list(docs.values())

    # L·∫•y nhi·ªÅu ƒëo·∫°n context
    top_indices = I[0]
    contexts = [docs[idx] for idx in top_indices if idx != -1 and idx < len(docs)]

    if contexts:
        context = "\n\n".join(contexts)
    else:
        context = "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p."

    # T·∫°o prompt cho OpenAI
    prompt = f"""
B·∫°n l√† chuy√™n gia k·ªπ thu·∫≠t b·∫£o tr√¨. D∆∞·ªõi ƒë√¢y l√† d·ªØ li·ªáu li√™n quan:

--- D·ªØ li·ªáu k·ªπ thu·∫≠t ---
{context}

--- C√¢u h·ªèi ---
{query}

Vui l√≤ng tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c, v√† d·ªÖ hi·ªÉu.
"""

    # Hi·ªÉn th·ªã d·ªØ li·ªáu d√πng
    st.subheader("üßæ C√°c ƒëo·∫°n d·ªØ li·ªáu ƒë∆∞·ª£c d√πng:")
    for i, c in enumerate(contexts):
        st.markdown(f"**ƒêo·∫°n {i+1}:**")
        st.code(c)

    # G·ªçi OpenAI GPT-3.5
    try:
        from openai import OpenAI
        client = OpenAI()

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )

        answer = response.choices[0].message.content.strip()

        st.markdown("### ü§ñ K·∫øt qu·∫£ t·ª´ AI:")
        st.success(answer)

        with st.expander("üìñ D·ªØ li·ªáu chu·∫©n b·ªã cho AI:"):
            st.code(context)

    except Exception as e:
        st.error(f"‚ùå L·ªói khi g·ªçi OpenAI: {e}")
