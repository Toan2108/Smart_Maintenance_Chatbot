import streamlit as st
import openai
import os
import pickle
import faiss
import numpy as np
import requests
import zipfile
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from utils import load_faiss_and_docs
import gdown

# --- H√†m t·∫£i v√† gi·∫£i n√©n m√¥ h√¨nh t·ª´ Google Drive ---
def download_and_extract_model():
    file_id = "https://drive.google.com/file/d/1DRWgv0tR2dBEWREsm3zgY5O2L6dlDm75/view?usp=sharing"
    zip_path = "local_model.zip"
    extract_folder = "local_model"

    if not os.path.exists(extract_folder):
        gdown.download(id=file_id, output=zip_path, quiet=False)
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_folder)
        os.remove(zip_path)

    return extract_folder

# --- Load m√¥ h√¨nh ---
model_path = download_and_extract_model()
model = SentenceTransformer(model_path)

# --- Load API key ---
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# --- C·∫•u h√¨nh Streamlit ---
st.set_page_config(page_title="AI Chatbot B·∫£o Tr√¨", layout="wide")
st.title("ü§ñ Smart Maintenance Chatbot")
st.markdown("Chatbot h·ªó tr·ª£ k·ªπ thu·∫≠t vi√™n tra c·ª©u l·ªói & h∆∞·ªõng x·ª≠ l√Ω t·ª´ d·ªØ li·ªáu hu·∫•n luy·ªán n·ªôi b·ªô.")

# --- Load FAISS index v√† d·ªØ li·ªáu ---
faiss_path, docs_path = load_faiss_and_docs()
with open(docs_path, "rb") as f:
    docs = pickle.load(f)

index = faiss.read_index(faiss_path)

# --- Nh·∫≠p c√¢u h·ªèi ---
query = st.text_input("üí¨ Nh·∫≠p c√¢u h·ªèi k·ªπ thu·∫≠t ho·∫∑c l·ªói m√°y m√≥c:")

if query:
    # Encode c√¢u h·ªèi v√† t√¨m top-k vƒÉn b·∫£n
    query_embedding = model.encode([query])
    D, I = index.search(np.array(query_embedding), k=3)

    # N·∫øu docs l√† dict th√¨ chuy·ªÉn sang list
    if isinstance(docs, dict):
        docs = list(docs.values())

    # L·∫•y ng·ªØ c·∫£nh t·ª´ top-k ƒëo·∫°n vƒÉn
    top_indices = I[0]
    contexts = [docs[i] for i in top_indices if i != -1 and i < len(docs)]
    context = "\n\n".join(contexts) if contexts else "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p."

    # Prompt cho OpenAI
    prompt = f"""
B·∫°n l√† chuy√™n gia k·ªπ thu·∫≠t b·∫£o tr√¨. D∆∞·ªõi ƒë√¢y l√† d·ªØ li·ªáu li√™n quan:

--- D·ªØ li·ªáu k·ªπ thu·∫≠t ---
{context}

--- C√¢u h·ªèi ---
{query}

Vui l√≤ng tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c, v√† d·ªÖ hi·ªÉu.
"""

    # Hi·ªÉn th·ªã ng·ªØ c·∫£nh ƒë√£ d√πng
    st.subheader("üìÑ C√°c ƒëo·∫°n d·ªØ li·ªáu ƒë∆∞·ª£c d√πng:")
    for i, c in enumerate(contexts):
        st.markdown(f"**ƒêo·∫°n {i+1}:**")
        st.code(c)

    # G·ªçi API OpenAI
    try:
        from openai import OpenAI
        client = OpenAI()

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        answer = response.choices[0].message.content.strip()
        st.markdown("### ü§ñ K·∫øt qu·∫£ t·ª´ AI:")
        st.success(answer)

        with st.expander("üìñ D·ªØ li·ªáu chu·∫©n b·ªã cho AI:"):
            st.code(context)

    except Exception as e:
        st.error(f"‚ùå L·ªói khi g·ªçi OpenAI: {e}")
