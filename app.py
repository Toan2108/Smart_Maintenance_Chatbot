import streamlit as st
import openai
import os
import pickle
import faiss
import numpy as np
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from utils import load_faiss_and_docs

# Load API Key t·ª´ .env ho·∫∑c secrets
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# C·∫•u h√¨nh Streamlit
st.set_page_config(page_title="AI Chatbot B·∫£o Tr√¨", layout="wide")
st.title("ü§ñ Smart Maintenance Chatbot")
st.markdown("Chatbot h·ªó tr·ª£ k·ªπ thu·∫≠t vi√™n tra c·ª©u l·ªói & h∆∞·ªõng x·ª≠ l√Ω t·ª´ d·ªØ li·ªáu hu·∫•n luy·ªán n·ªôi b·ªô.")

# B∆∞·ªõc 1: T·∫£i d·ªØ li·ªáu t·ª´ Google Drive n·∫øu ch∆∞a c√≥
faiss_path, docs_path = load_faiss_and_docs()

# B∆∞·ªõc 2: Load FAISS index v√† d·ªØ li·ªáu g·ªëc
with open(docs_path, "rb") as f:
    docs = pickle.load(f)

index = faiss.read_index(faiss_path)

# B∆∞·ªõc 3: Nh·∫≠n c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
query = st.text_input("üí¨ Nh·∫≠p c√¢u h·ªèi k·ªπ thu·∫≠t ho·∫∑c l·ªói m√°y m√≥c:")

if query:
    # Encode c√¢u h·ªèi
    model = SentenceTransformer("paraphrase-MiniLM-L6-v2")
    query_embedding = model.encode([query])

# T√¨m vƒÉn b·∫£n g·∫ßn nh·∫•t
    D, I = index.search(np.array(query_embedding), k=3)
# N·∫øu docs l√† dict th√¨ chuy·ªÉn sang list
if isinstance(docs, dict):
    docs = list(docs.values())

# L·∫•y nhi·ªÅu ƒëo·∫°n context t·ª´ ch·ªâ s·ªë tr·∫£ v·ªÅ (k=3)
top_indices = I[0]
contexts = []

for idx in top_indices:
    if idx != -1 and idx < len(docs):
        contexts.append(docs[idx])

if contexts:
    context = "\n\n".join(contexts)
else:
    context = "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p."

    # T·∫°o prompt cho OpenAI
    prompt = f"""
B·∫°n l√† chuy√™n gia k·ªπ thu·∫≠t b·∫£o tr√¨. D∆∞·ªõi ƒë√¢y l√† d·ªØ li·ªáu li√™n quan:

--- D·ªØ li·ªáu k·ªπ thu·∫≠t ---
{context}

--- C√¢u h·ªèi ---
{query}

Vui l√≤ng tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c, v√† d·ªÖ hi·ªÉu.
"""
st.subheader("üßæ C√°c ƒëo·∫°n d·ªØ li·ªáu ƒë∆∞·ª£c d√πng:")
for i, c in enumerate(contexts):
    st.markdown(f"**ƒêo·∫°n {i+1}:**")
    st.code(c)

    # G·ªçi API GPT-3.5
# G·ªçi API GPT-3.5
try:
    from openai import OpenAI
    client = OpenAI()

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": prompt}
        ]
    )

    answer = response.choices[0].message.content.strip()

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    st.markdown("### ü§ñ K·∫øt qu·∫£ t·ª´ AI:")
    st.success(answer)

    with st.expander("üìñ D·ªØ li·ªáu chu·∫©n b·ªã cho AI:"):
        st.code(context)

except Exception as e:
    st.error(f"‚ùå L·ªói khi g·ªçi OpenAI: {e}")

