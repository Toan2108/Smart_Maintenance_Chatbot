import streamlit as st
import openai
import os
os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["HF_HOME"] = "/tmp"  # n∆°i l∆∞u cache model
os.environ["HF_DATASETS_CACHE"] = "/tmp"
os.environ["HF_METRICS_CACHE"] = "/tmp"

import numpy as np
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer

@st.cache_resource
def load_model():
    model = SentenceTransformer("all-MiniLM-L6-v2")
    return model

from sklearn.preprocessing import normalize
from utils import load_faiss_and_docs

# ‚úÖ Load API Key
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ‚úÖ C·∫•u h√¨nh giao di·ªán
st.set_page_config(page_title="Smart Maintenance Chatbot", layout="wide")
st.title("ü§ñ Smart Maintenance Chatbot")
st.markdown("Nh·∫≠p c√¢u h·ªèi k·ªπ thu·∫≠t ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ t·ª´ d·ªØ li·ªáu n·ªôi b·ªô ƒë√£ hu·∫•n luy·ªán.")

# ‚úÖ Load d·ªØ li·ªáu FAISS v√† vƒÉn b·∫£n
index, docs = load_faiss_and_docs("/tmp/index.faiss", "/tmp/docs.pkl")

# ‚úÖ Load m√¥ h√¨nh embedding
model = SentenceTransformer("all-mpnet-base-v2")

# ‚úÖ Nh·∫≠p c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
query = st.text_input("üõ†Ô∏è Nh·∫≠p c√¢u h·ªèi k·ªπ thu·∫≠t:")

if query:
    query_embedding = model.encode([query])
    query_embedding = normalize(query_embedding, axis=1)

    D, I = index.search(query_embedding, k=3)

    contexts = []
    for idx in I[0]:
        if 0 <= idx < len(docs):
            contexts.append(docs[idx])

    if not contexts:
        st.error("Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p.")
    else:
        st.subheader("üìé T√†i li·ªáu tham chi·∫øu:")
        for i, ctx in enumerate(contexts):
            st.markdown(f"**{i+1}.** {ctx}")

        context_text = "\n\n".join(contexts)
        prompt = f"""
B·∫°n l√† chuy√™n gia k·ªπ thu·∫≠t. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë th√¥ng tin k·ªπ thu·∫≠t n·ªôi b·ªô:

{context_text}

C√¢u h·ªèi: {query}
Vui l√≤ng tr·∫£ l·ªùi ch√≠nh x√°c, r√µ r√†ng, ng·∫Øn g·ªçn.
"""

        try:
            from openai import OpenAI
            client = OpenAI()

            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}]
            )
            answer = response.choices[0].message.content.strip()
            st.success(answer)
        except Exception as e:
            st.error(f"L·ªói khi g·ªçi OpenAI API: {e}")
