import streamlit as st
import openai
import os
import pickle
import faiss
import numpy as np
import requests
import zipfile
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from utils import load_faiss_and_docs
import gdown

def download_and_extract_model():
    # Link Google Drive d·∫°ng ID (ƒë√£ c√≥ quy·ªÅn chia s·∫ª c√¥ng khai)
    file_id = "1GwQQmdZ2O2wGixLKiRk9MiMtBfToozll"
    zip_path = "local_model.zip"
    extract_folder = "local_model"

    if not os.path.exists(extract_folder):
        gdown.download(id=file_id, output=zip_path, quiet=False)

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_folder)
        os.remove(zip_path)

    return extract_folder

# --- T·∫£i m√¥ h√¨nh t·ª´ Google Drive ---
def download_and_extract_model():
    model_url = "https://drive.google.com/uc?id=1GwQQmdZ2O2wGixLKiRk9MiMtBfToozll"
    zip_path = "local_model.zip"
    extract_folder = "local_model"

    if not os.path.exists(extract_folder):
        with requests.get(model_url, stream=True) as r:
            with open(zip_path, "wb") as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_folder)
        os.remove(zip_path)

    return extract_folder

# --- T·∫£i model ---
model_path = download_and_extract_model()
model = SentenceTransformer(model_path)

# --- Load API key ---
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# --- C·∫•u h√¨nh Streamlit ---
st.set_page_config(page_title="AI Chatbot B·∫£o Tr√¨", layout="wide")
st.title("ü§ñ Smart Maintenance Chatbot")
st.markdown("Chatbot h·ªó tr·ª£ k·ªπ thu·∫≠t vi√™n tra c·ª©u l·ªói & h∆∞·ªõng x·ª≠ l√Ω t·ª´ d·ªØ li·ªáu hu·∫•n luy·ªán n·ªôi b·ªô.")

# --- Load FAISS index v√† docs ---
faiss_path, docs_path = load_faiss_and_docs()
with open(docs_path, "rb") as f:
    docs = pickle.load(f)
index = faiss.read_index(faiss_path)

# --- Nh·∫≠n c√¢u h·ªèi ---
query = st.text_input("üí¨ Nh·∫≠p c√¢u h·ªèi k·ªπ thu·∫≠t ho·∫∑c l·ªói m√°y m√≥c:")

if query:
    query_embedding = model.encode([query])
    D, I = index.search(np.array(query_embedding), k=3)

    if isinstance(docs, dict):
        docs = list(docs.values())

    top_indices = I[0]
    contexts = [docs[i] for i in top_indices if i != -1 and i < len(docs)]

    if contexts:
        context = "\n\n".join(contexts)
    else:
        context = "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p."

    prompt = f"""
B·∫°n l√† chuy√™n gia k·ªπ thu·∫≠t b·∫£o tr√¨. D∆∞·ªõi ƒë√¢y l√† d·ªØ li·ªáu li√™n quan:

--- D·ªØ li·ªáu k·ªπ thu·∫≠t ---
{context}

--- C√¢u h·ªèi ---
{query}

Vui l√≤ng tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c, v√† d·ªÖ hi·ªÉu.
"""

    st.subheader("üßæ C√°c ƒëo·∫°n d·ªØ li·ªáu ƒë∆∞·ª£c d√πng:")
    for i, c in enumerate(contexts):
        st.markdown(f"**ƒêo·∫°n {i+1}:**")
        st.code(c)

    try:
        from openai import OpenAI
        client = OpenAI()

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        answer = response.choices[0].message.content.strip()
        st.markdown("### ü§ñ K·∫øt qu·∫£ t·ª´ AI:")
        st.success(answer)

        with st.expander("üìñ D·ªØ li·ªáu chu·∫©n b·ªã cho AI:"):
            st.code(context)

    except Exception as e:
        st.error(f"‚ùå L·ªói khi g·ªçi OpenAI: {e}")
